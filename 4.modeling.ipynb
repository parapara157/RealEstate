{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "import seaborn as sns\n",
    "import estateFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###경제상황을 반영해주기 위해 각종 지수들을 넣어줌.\n",
    "\n",
    "###공동주택 실거래 가격지수 아파트 \n",
    "apartIndex=pd.read_csv(\"indexData/apartIndex.csv\",encoding=\"cp949\")\n",
    "apartIndex=list((apartIndex.iloc[10].reset_index())[10])[2:]\n",
    "###경기종합 선행 지수\n",
    "economicIndex=pd.read_csv(\"indexData/economicPredictionIndex.csv\",encoding=\"cp949\")\n",
    "economicIndex=list((economicIndex.iloc[10].reset_index()[10])[1:])\n",
    "###생산자 물가 지수\n",
    "produceIndex=pd.read_csv(\"indexData/produceIndex.csv\",encoding=\"cp949\")\n",
    "produceIndex=list((produceIndex.iloc[10].reset_index()[10])[1:])\n",
    "###소비자 물가 지수\n",
    "spendIndex=pd.read_csv(\"indexData/spendIndex.csv\",encoding=\"cp949\")\n",
    "spendIndex=list((spendIndex.iloc[10].reset_index()[10])[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###2018/12데이터를 예측하므로 2018/11까지 있어야됨\n",
    "###2018/12데이터에는 2018/11데이터넣음\n",
    "###2010/01데이터에는 2009/12데이터넣음\n",
    "def makeApartIndex(x):\n",
    "    index=(x-201001)//100*12+(x-201001)%100\n",
    "    return apartIndex[index]\n",
    "def makeEconomicIndex(x):\n",
    "    index=(x-201001)//100*12+(x-201001)%100\n",
    "    return economicIndex[index]\n",
    "def makeSpendIndex(x):\n",
    "    index=(x-201001)//100*12+(x-201001)%100\n",
    "    return spendIndex[index]\n",
    "def makeProduceIndex(x):\n",
    "    index=(x-201001)//100*12+(x-201001)%100\n",
    "    return produceIndex[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldData=pd.read_csv(\"dataAfterPreprocess/finaltrain\")  \n",
    "kfoldTarget=kfoldData['거래금액(만원)']\n",
    "#target값 삭제해주고 나머지 변수들은 훈련에 사용될 수 없음\n",
    "del kfoldData['거래금액(만원)']\n",
    "del kfoldData['시군구']\n",
    "del kfoldData['번지']\n",
    "del kfoldData['본번']\n",
    "del kfoldData['부번']\n",
    "###object에서 category로 바꾸어주어야함\n",
    "kfoldData['단지명']=kfoldData['단지명'].astype('category')\n",
    "kfoldData['도로명']=kfoldData['도로명'].astype('category')\n",
    "kfoldData['big']=kfoldData['big'].astype('category')\n",
    "kfoldData['small']=kfoldData['small'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldData['apartIndex']=kfoldData['계약년월'].apply(makeApartIndex).astype('float')\n",
    "kfoldData['economicIndex']=kfoldData['계약년월'].apply(makeEconomicIndex).astype('float')\n",
    "kfoldData['spendIndex']=kfoldData['계약년월'].apply(makeSpendIndex).astype('float')\n",
    "kfoldData['produceIndex']=kfoldData['계약년월'].apply(makeProduceIndex).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldTest=pd.read_csv(\"dataAfterPreprocess/finaltest\")\n",
    "testTarget=kfoldTest[\"거래금액(만원)\"]/kfoldTest['전용면적(㎡)']\n",
    "#target값 삭제해주고 나머지 변수들은 훈련에 사용될 수 없음\n",
    "del kfoldTest['거래금액(만원)']\n",
    "del kfoldTest['시군구']\n",
    "del kfoldTest['번지']\n",
    "del kfoldTest['본번']\n",
    "del kfoldTest['부번']\n",
    "del kfoldTest['공시가격']\n",
    "del kfoldTest['공시가격(만원)']\n",
    "###object에서 category로 바꾸어주어야함\n",
    "kfoldTest['단지명']=kfoldTest['단지명'].astype('category')\n",
    "kfoldTest['도로명']=kfoldTest['도로명'].astype('category')\n",
    "kfoldTest['big']=kfoldTest['big'].astype('category')\n",
    "kfoldTest['small']=kfoldTest['small'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldTest['apartIndex']=kfoldTest['계약년월'].apply(makeApartIndex).astype('float')\n",
    "kfoldTest['economicIndex']=kfoldTest['계약년월'].apply(makeEconomicIndex).astype('float')\n",
    "kfoldTest['spendIndex']=kfoldTest['계약년월'].apply(makeSpendIndex).astype('float')\n",
    "kfoldTest['produceIndex']=kfoldTest['계약년월'].apply(makeProduceIndex).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldData.columns=['Apart name','USM','Sold date','Storey','Build year','Street name','latitude','longitude','District','dong',\n",
    "                   'Sold month','Apart index','Leading index','Consumer index', 'Producer index']\n",
    "kfoldTest.columns=['Apart name','USM','Sold date','Storey','Build year','Street name','latitude','longitude','District','dong',\n",
    "                   'Sold month','Apart index','Leading index','Consumer index', 'Producer index']\n",
    "###ppsm으로 고쳐줘야 되므로\n",
    "kfoldTarget=kfoldTarget/kfoldData['USM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554312, 554312, 1393, 1393)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kfoldData),len(kfoldTarget),len(kfoldTest),len(testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST=sum((testTarget-np.mean(testTarget))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###big제외하고 원핫인코딩하기에는 너무 많다.\n",
    "kfoldDataWithBig=copy.deepcopy(kfoldData)\n",
    "kfoldTestWithBig=copy.deepcopy(kfoldTest)\n",
    "del kfoldDataWithBig['Apart name']\n",
    "del kfoldDataWithBig['Street name']\n",
    "del kfoldDataWithBig['dong']\n",
    "del kfoldTestWithBig['Apart name']\n",
    "del kfoldTestWithBig['Street name']\n",
    "del kfoldTestWithBig['dong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['District'] \n",
    "\n",
    "for column in cat_features:\n",
    "    temp = pd.get_dummies(pd.Series(kfoldDataWithBig[column])) \n",
    "    kfoldDataWithBig = pd.concat([kfoldDataWithBig,temp],axis=1) \n",
    "    kfoldDataWithBig = kfoldDataWithBig.drop([column],axis=1) \n",
    "\n",
    "for column in cat_features: \n",
    "    temp = pd.get_dummies(pd.Series(kfoldTestWithBig[column])) \n",
    "    kfoldTestWithBig = pd.concat([kfoldTestWithBig,temp],axis=1) \n",
    "    kfoldTestWithBig = kfoldTestWithBig.drop([column],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-131192.15449393567,\n",
       " array([-1.16479458e+00,  7.77454988e-02,  5.84953234e+00,  1.18272560e+00,\n",
       "         1.51192143e+03,  4.53427989e+02,  1.01912973e+00,  9.71996600e-01,\n",
       "         2.50740539e+01, -4.72872807e+01,  1.57624570e+01,  6.09856443e+02,\n",
       "        -4.78333598e+01, -3.08584535e+02, -3.66521102e+01,  1.40682899e+01,\n",
       "         5.48852010e+01, -2.48995873e+01, -2.73540415e+01, -3.43446120e+02,\n",
       "        -3.92116847e+02, -1.92632758e+02,  1.25412681e+02,  1.01796672e+02,\n",
       "        -1.07887041e+02,  4.99537808e+02,  5.69988991e+01, -2.20765511e+02,\n",
       "         2.65974723e+02,  1.18365738e+02,  7.92028254e+01,  3.00958412e+02,\n",
       "        -1.87463938e+02, -3.57760689e+01,  5.11911551e+00, -3.06764890e+02]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=LinearRegression()\n",
    "reg.fit(kfoldDataWithBig,kfoldTarget)\n",
    "olsPre=reg.predict(kfoldTestWithBig)\n",
    "olsOof=reg.predict(kfoldDataWithBig)\n",
    "reg.intercept_,reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1393.000000\n",
       "mean       18.668295\n",
       "std        16.988034\n",
       "min         0.014343\n",
       "25%         6.556310\n",
       "50%        14.655353\n",
       "75%        25.470564\n",
       "max       162.819954\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(testTarget-olsPre)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6481738097326828"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sum((testTarget-olsPre)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "###randomforest 단일모델\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfOof = np.zeros(len(kfoldDataWithBig))\n",
    "rfPre = np.zeros(len(kfoldTestWithBig)) \n",
    "folds=KFold(n_splits=5,shuffle=True,random_state=15)\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(kfoldDataWithBig,kfoldTarget)) : \n",
    "    print(n_fold)\n",
    "    trn_x, trn_y = kfoldDataWithBig.iloc[trn_idx], kfoldTarget[trn_idx] \n",
    "    val_x, val_y = kfoldDataWithBig.iloc[val_idx], kfoldTarget[val_idx] \n",
    "    ranFo=RandomForestRegressor(n_estimators=1500, max_leaf_nodes=15, n_jobs=-1,max_features=\"sqrt\")\n",
    "    ranFo.fit(trn_x,trn_y)\n",
    "    \n",
    "    rfOof[val_idx]=ranFo.predict(val_x)\n",
    "    rfPre+=ranFo.predict(kfoldTestWithBig)/folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(testTarget-rfPre)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum((testTarget-rfPre)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###xgboost 단일모델 \n",
    "xgboost.train(params, dtrain, num_boost_round=10, \n",
    "              evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, \n",
    "              evals_result=None, verbose_eval=True, xgb_model=None, callbacks=None, learning_rates=None)\n",
    "evals (list of pairs (DMatrix, string)) – List of validation sets for which metrics will evaluated during training. \n",
    "Validation metrics will help us track the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###범주형 변수 big만 남겼음\n",
    "###속도가 빨라짐\n",
    "print(\"xgboost\") \n",
    "xgbOof = np.zeros(len(kfoldDataWithBig))\n",
    "xgbPre = np.zeros(len(kfoldTestWithBig)) \n",
    "folds=KFold(n_splits=5,shuffle=True,random_state=15)\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(kfoldDataWithBig,kfoldTarget)) : \n",
    "    trn_x, trn_y = kfoldDataWithBig.iloc[trn_idx], kfoldTarget[trn_idx] \n",
    "    val_x, val_y = kfoldDataWithBig.iloc[val_idx], kfoldTarget[val_idx] \n",
    "    params = {'objective': 'reg:linear', \n",
    "              'booster':'gbtree',                   ###Tree base 모델\n",
    "              'eval_metric': 'mae', \n",
    "              'eta': 0.1,           ###학습속도 일반적으로 0.01~0.2\n",
    "              'max_depth': 10,    ###트리 최대깊이 일반적으로 3~10\n",
    "              'subsample': 0.9,    ###각 트리마다 관측 데이터 샘플링 비율 0.5~1\n",
    "              'colsample_bytree': 0.9,   ###각 트리마다 변수 샘플링 비율 0.5~1\n",
    "              'alpha':0.001,                    ###규제항 \n",
    "              'random_state': 42, \n",
    "              'verbosity': 1}                ###동작메시지 출력\n",
    "    tr_data = xgb.DMatrix(trn_x, trn_y) \n",
    "    va_data = xgb.DMatrix(val_x, val_y) \n",
    "    watchlist = [(tr_data, 'train'), (va_data, 'valid')] \n",
    "    model_xgb = xgb.train(params, tr_data, 10000, watchlist, maximize=False, early_stopping_rounds = 500, verbose_eval=100) \n",
    "    \n",
    "    test_data = xgb.DMatrix(kfoldTestWithBig) \n",
    "    xgbPre += model_xgb.predict(test_data) / folds.n_splits \n",
    "    xgbOof[val_idx] = model_xgb.predict(va_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(testTarget-xgbPre)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum((testTarget-xgbPre)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###lightgbm 파라미터\n",
    "param = {'num_leaves': 50,               \n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.2,           ###트리만들때마다 0.01 씩 가중치 곱함\n",
    "         \"boosting\": \"gbdt\",                ###워래 우리가 아는 gbdt 씀\n",
    "         \"feature_fraction\": 0.9,          ###변수 90%만 쓰게됨\n",
    "         \"bagging_freq\": 1,                 ###bagging 의빈도\n",
    "         \"bagging_fraction\": 0.9,        ###데이터를 90%만 쓰게됨 resampling 없이\n",
    "         \"bagging_seed\": 11,              ###bagging 을 위한 seed\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 0.1,                  ###오메가 항에서 람다 말할는거임 가중치 옆에 붙는 weights 숫자가 클수록 보수적\n",
    "         \"verbosity\": -1}                      ###보수적이라는말은 트리생성을 잘안할려고함\n",
    "###verbosity -1이 정확하게 어떤기능인지?\n",
    "###bagging을 실행하는데 어떠한 순서로 실행하는건지?\n",
    "###처음에 데이터가있으면\n",
    "###처음에 부스팅 한번할때마다 배깅을 실행한다고한다\n",
    "###즉 kfold에 의해서 트레인데이터가들어오면\n",
    "###이 트레인에서 변수90% 데이터 90% 를뽑는다\n",
    "###이걸로 트리하나만듬 \n",
    "###이때 트리를 총 10개만든다는 소리인가? 그래서 배깅을함???\n",
    "###그뒤에 10개의 weight 값 얻고 난뒤에 learningrate 적용해서 잔차계산하는건가???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm단일모델인데 범주형 변수 제외하고 이거는 가변수 쓰지말고 그냥 big 그대로 쓰자\n",
    "lightgbmOof=np.zeros(len(kfoldDataWithBig))\n",
    "lightgbmPre=np.zeros(len(kfoldTestWithBig))\n",
    "kfoldData2=copy.deepcopy(kfoldData)\n",
    "kfoldTest2=copy.deepcopy(kfoldTest)\n",
    "del kfoldData2['Apart name']\n",
    "del kfoldData2['Street name']\n",
    "del kfoldData2['dong']\n",
    "del kfoldTest2['Apart name']\n",
    "del kfoldTest2['Street name']\n",
    "del kfoldTest2['dong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=KFold(n_splits=5,shuffle=True,random_state=15)\n",
    "feature_importance_df = pd.DataFrame()\n",
    "features=kfoldData2.columns\n",
    "for order, (train_idx,valid_idx) in enumerate(folds.split(kfoldData2, kfoldTarget)):\n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(order + 1))\n",
    "    trn_data = lgb.Dataset(kfoldData2.iloc[train_idx], label=kfoldTarget.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(kfoldData2.iloc[valid_idx], label=kfoldTarget.iloc[valid_idx])\n",
    "\n",
    "    num_round = 10000          ###boosting 10000번 한다는소리임 verbose_eval 은 100번마다 출력함\n",
    "    ###early는 100번동안 효과없으면 그만둠\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], verbose_eval=100, early_stopping_rounds=100)\n",
    "    #훈련해서 모수가 조정된 모델에 valid 데이터 넣어서 예측값 보여주는것\n",
    "    lightgbmOof[valid_idx] = clf.predict(kfoldData2.iloc[valid_idx], num_iteration=clf.best_iteration)\n",
    "    ###5개모델 다더해서 나누면 최종 예측치 되는것\n",
    "    lightgbmPre += clf.predict(kfoldTest2, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"]=features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"order\"] = order + 1\n",
    "    \n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:20].index)\n",
    "###각변수들 평규내서 위에서 상위 1000개뽑는것 근디 총변수가 180개인데 의미있나?\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "                ###900개중에서 해당하는 변수가 중복으로 뽑히게됨 결과로 보니 그런듯\n",
    "    ###그런데 그림으로 그릴때는 이게 합쳐지는듯\n",
    "plt.figure(figsize=(10,15))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(testTarget-lightgbmPre)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum((testTarget-lightgbmPre)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###lightgbm 데이터 다쓰는것 범주형 다쓰는거임\n",
    "lightgbmOof2=np.zeros(len(kfoldData))\n",
    "lightgbmPre2=np.zeros(len(kfoldTest))\n",
    "folds=KFold(n_splits=5,shuffle=True,random_state=15)\n",
    "feature_importance_df2 = pd.DataFrame()\n",
    "features2=kfoldData.columns\n",
    "for order, (train_idx,valid_idx) in enumerate(folds.split(kfoldData, kfoldTarget)):\n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(order + 1))\n",
    "    trn_data = lgb.Dataset(kfoldData.iloc[train_idx], label=kfoldTarget.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(kfoldData.iloc[valid_idx], label=kfoldTarget.iloc[valid_idx])\n",
    "\n",
    "    num_round = 10000          ###boosting 10000번 한다는소리임 verbose_eval 은 100번마다 출력함\n",
    "    ###early는 100번동안 효과없으면 그만둠\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], verbose_eval=100, early_stopping_rounds=100)\n",
    "    #훈련해서 모수가 조정된 모델에 valid 데이터 넣어서 예측값 보여주는것\n",
    "    lightgbmOof2[valid_idx] = clf.predict(kfoldData.iloc[valid_idx], num_iteration=clf.best_iteration)\n",
    "    ###5개모델 다더해서 나누면 최종 예측치 되는것\n",
    "    lightgbmPre2 += clf.predict(kfoldTest, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df2 = pd.DataFrame()\n",
    "    fold_importance_df2[\"feature\"]=features2\n",
    "    fold_importance_df2[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df2[\"order\"] = order + 1\n",
    "    \n",
    "    feature_importance_df2 = pd.concat([feature_importance_df2, fold_importance_df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df2[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:30].index)\n",
    "###각변수들 평규내서 위에서 상위 1000개뽑는것 근디 총변수가 180개인데 의미있나?\n",
    "best_features = feature_importance_df2.loc[feature_importance_df2.feature.isin(cols)]\n",
    "                ###900개중에서 해당하는 변수가 중복으로 뽑히게됨 결과로 보니 그런듯\n",
    "    ###그런데 그림으로 그릴때는 이게 합쳐지는듯\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"importance\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm단일모델 범주형 다씀\n",
    "(abs(testTarget-lightgbmPre2)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum((testTarget-lightgbmPre2)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
