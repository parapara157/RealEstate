{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "import seaborn as sns\n",
    "import estateFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###경제상황을 반영해주기 위해 각종 지수들을 넣어줌.\n",
    "\n",
    "###공동주택 실거래 가격지수 아파트 \n",
    "apartIndex=pd.read_csv(\"indexData/apartIndex.csv\",encoding=\"cp949\")\n",
    "apartIndex=list((apartIndex.iloc[10].reset_index())[10])[2:]\n",
    "###경기종합 선행 지수\n",
    "economicIndex=pd.read_csv(\"indexData/economicPredictionIndex.csv\",encoding=\"cp949\")\n",
    "economicIndex=list((economicIndex.iloc[10].reset_index()[10])[1:])\n",
    "###생산자 물가 지수\n",
    "produceIndex=pd.read_csv(\"indexData/produceIndex.csv\",encoding=\"cp949\")\n",
    "produceIndex=list((produceIndex.iloc[10].reset_index()[10])[1:])\n",
    "###소비자 물가 지수\n",
    "spendIndex=pd.read_csv(\"indexData/spendIndex.csv\",encoding=\"cp949\")\n",
    "spendIndex=list((spendIndex.iloc[10].reset_index()[10])[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###2018/12데이터를 예측하므로 2018/11까지 있어야됨\n",
    "###2018/12데이터에는 2018/11데이터넣음\n",
    "###2010/01데이터에는 2009/12데이터넣음\n",
    "def makeApartIndex(x):\n",
    "    index=(x-201001)//100*12+(x-201001)%100\n",
    "    return apartIndex[index]\n",
    "def makeEconomicIndex(x):\n",
    "    index=(x-201001)//100*12+(x-201001)%100\n",
    "    return economicIndex[index]\n",
    "def makeSpendIndex(x):\n",
    "    index=(x-201001)//100*12+(x-201001)%100\n",
    "    return spendIndex[index]\n",
    "def makeProduceIndex(x):\n",
    "    index=(x-201001)//100*12+(x-201001)%100\n",
    "    return produceIndex[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldData=pd.read_csv(\"dataAfterPreprocess/finaltrain\")  \n",
    "kfoldTarget=kfoldData['거래금액(만원)']\n",
    "#target값 삭제해주고 나머지 변수들은 훈련에 사용될 수 없음\n",
    "del kfoldData['거래금액(만원)']\n",
    "del kfoldData['시군구']\n",
    "del kfoldData['번지']\n",
    "del kfoldData['본번']\n",
    "del kfoldData['부번']\n",
    "###object에서 category로 바꾸어주어야함\n",
    "kfoldData['단지명']=kfoldData['단지명'].astype('category')\n",
    "kfoldData['도로명']=kfoldData['도로명'].astype('category')\n",
    "kfoldData['big']=kfoldData['big'].astype('category')\n",
    "kfoldData['small']=kfoldData['small'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldData['apartIndex']=kfoldData['date'].apply(makeApartIndex).astype('float')\n",
    "kfoldData['economicIndex']=kfoldData['date'].apply(makeEconomicIndex).astype('float')\n",
    "kfoldData['spendIndex']=kfoldData['date'].apply(makeSpendIndex).astype('float')\n",
    "kfoldData['produceIndex']=kfoldData['date'].apply(makeProduceIndex).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldTest=pd.read_csv(\"dataAfterPreprocess/finaltest\")\n",
    "testTarget=kfoldTest[\"거래금액(만원)\"]/kfoldTest['전용면적(㎡)']\n",
    "#target값 삭제해주고 나머지 변수들은 훈련에 사용될 수 없음\n",
    "del kfoldTest['거래금액(만원)']\n",
    "del kfoldTest['시군구']\n",
    "del kfoldTest['번지']\n",
    "del kfoldTest['본번']\n",
    "del kfoldTest['부번']\n",
    "del kfoldTest['공시가격']\n",
    "del kfoldTest['공시가격(만원)']\n",
    "###object에서 category로 바꾸어주어야함\n",
    "kfoldTest['단지명']=kfoldTest['단지명'].astype('category')\n",
    "kfoldTest['도로명']=kfoldTest['도로명'].astype('category')\n",
    "kfoldTest['big']=kfoldTest['big'].astype('category')\n",
    "kfoldTest['small']=kfoldTest['small'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldTest['apartIndex']=kfoldData['date'].apply(makeApartIndex).astype('float')\n",
    "kfoldTest['economicIndex']=kfoldData['date'].apply(makeEconomicIndex).astype('float')\n",
    "kfoldTest['spendIndex']=kfoldData['date'].apply(makeSpendIndex).astype('float')\n",
    "kfoldTest['produceIndex']=kfoldData['date'].apply(makeProduceIndex).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ppsm으로 고쳐줘야 되므로\n",
    "kfoldTarget=kfoldTarget/kfoldData['square']\n",
    "kfoldData.columns=['Apart name','USM','Sold date','Storey','Build year','Street name','latitude','longitude','District','dong',\n",
    "                   'Sold month','Apart index','Leading index','Consumer index', 'Producer index']\n",
    "kfoldTest.columns=['Apart name','USM','Sold date','Storey','Build year','Street name','latitude','longitude','District','dong',\n",
    "                   'Sold month','Apart index','Leading index','Consumer index', 'Producer index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554312, 554312, 1393, 1393)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kfoldData),len(kfoldTarget),len(kfoldTest),len(testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST=sum((testTarget-np.mean(testTarget))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###big제외하고 원핫인코딩하기에는 너무 많다.\n",
    "kfoldDataWithBig=copy.deepcopy(kfoldData)\n",
    "kfoldTestWithBig=copy.deepcopy(kfoldTest)\n",
    "del kfoldDataWithBig['Apart name']\n",
    "del kfoldDataWithBig['Street name']\n",
    "del kfoldDataWithBig['dong']\n",
    "del kfoldTestWithBig['Apart name']\n",
    "del kfoldTestWithBig['Street name']\n",
    "del kfoldTestWithBig['dong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['District'] \n",
    "\n",
    "for column in cat_features:\n",
    "    temp = pd.get_dummies(pd.Series(kfoldDataWithBig[column])) \n",
    "    kfoldDataWithBig = pd.concat([kfoldDataWithBig,temp],axis=1) \n",
    "    kfoldDataWithBig = kfoldDataWithBig.drop([column],axis=1) \n",
    "\n",
    "for column in cat_features: \n",
    "    temp = pd.get_dummies(pd.Series(kfoldTestWithBig[column])) \n",
    "    kfoldTestWithBig = pd.concat([kfoldTestWithBig,temp],axis=1) \n",
    "    kfoldTestWithBig = kfoldTestWithBig.drop([column],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-131192.15449393567,\n",
       " array([-1.16479458e+00,  7.77454988e-02,  5.84953234e+00,  1.18272560e+00,\n",
       "         1.51192143e+03,  4.53427989e+02,  1.01912973e+00,  9.71996600e-01,\n",
       "         2.50740539e+01, -4.72872807e+01,  1.57624570e+01,  6.09856443e+02,\n",
       "        -4.78333598e+01, -3.08584535e+02, -3.66521102e+01,  1.40682899e+01,\n",
       "         5.48852010e+01, -2.48995873e+01, -2.73540415e+01, -3.43446120e+02,\n",
       "        -3.92116847e+02, -1.92632758e+02,  1.25412681e+02,  1.01796672e+02,\n",
       "        -1.07887041e+02,  4.99537808e+02,  5.69988991e+01, -2.20765511e+02,\n",
       "         2.65974723e+02,  1.18365738e+02,  7.92028254e+01,  3.00958412e+02,\n",
       "        -1.87463938e+02, -3.57760689e+01,  5.11911551e+00, -3.06764890e+02]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OLS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg=LinearRegression()\n",
    "reg.fit(kfoldDataWithBig,kfoldTarget)\n",
    "olsPre=reg.predict(kfoldTestWithBig)\n",
    "olsOof=reg.predict(kfoldDataWithBig)\n",
    "reg.intercept_,reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1393.000000\n",
       "mean       22.984058\n",
       "std        20.643338\n",
       "min         0.005265\n",
       "25%         7.885094\n",
       "50%        17.630760\n",
       "75%        32.230105\n",
       "max       180.903481\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(testTarget-olsPre)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testTarget' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c5d40480bf71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestTarget\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0molsPre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mSST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'testTarget' is not defined"
     ]
    }
   ],
   "source": [
    "1-sum((testTarget-olsPre)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-14ddb9c73cef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m###randomforest 단일모델\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrfOof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkfoldDataWithBig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrfPre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkfoldTestWithBig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m _DEFAULT_TAGS = {\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###randomforest 단일모델\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfOof = np.zeros(len(kfoldDataWithBig))\n",
    "rfPre = np.zeros(len(kfoldTestWithBig)) \n",
    "folds=KFold(n_splits=5,shuffle=True,random_state=15)\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(kfoldDataWithBig,kfoldTarget)) : \n",
    "    print(n_fold)\n",
    "    trn_x, trn_y = kfoldDataWithBig.iloc[trn_idx], kfoldTarget[trn_idx] \n",
    "    val_x, val_y = kfoldDataWithBig.iloc[val_idx], kfoldTarget[val_idx] \n",
    "    ranFo=RandomForestRegressor(n_estimators=1500, max_leaf_nodes=15, n_jobs=-1,max_features=\"sqrt\")\n",
    "    ranFo.fit(trn_x,trn_y)\n",
    "    \n",
    "    rfOof[val_idx]=ranFo.predict(val_x)\n",
    "    rfPre+=ranFo.predict(kfoldTestWithBig)/folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(testTarget-rfPre)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum((testTarget-rfPre)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###xgboost 단일모델 \n",
    "xgboost.train(params, dtrain, num_boost_round=10, \n",
    "              evals=(), obj=None, feval=None, maximize=False, early_stopping_rounds=None, \n",
    "              evals_result=None, verbose_eval=True, xgb_model=None, callbacks=None, learning_rates=None)\n",
    "evals (list of pairs (DMatrix, string)) – List of validation sets for which metrics will evaluated during training. \n",
    "Validation metrics will help us track the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###범주형 변수 big만 남겼음\n",
    "###속도가 빨라짐\n",
    "print(\"xgboost\") \n",
    "xgbOof = np.zeros(len(kfoldDataWithBig))\n",
    "xgbPre = np.zeros(len(kfoldTestWithBig)) \n",
    "folds=KFold(n_splits=5,shuffle=True,random_state=15)\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(kfoldDataWithBig,kfoldTarget)) : \n",
    "    trn_x, trn_y = kfoldDataWithBig.iloc[trn_idx], kfoldTarget[trn_idx] \n",
    "    val_x, val_y = kfoldDataWithBig.iloc[val_idx], kfoldTarget[val_idx] \n",
    "    params = {'objective': 'reg:linear', \n",
    "              'booster':'gbtree',                   ###Tree base 모델\n",
    "              'eval_metric': 'mae', \n",
    "              'eta': 0.1,           ###학습속도 일반적으로 0.01~0.2\n",
    "              'max_depth': 10,    ###트리 최대깊이 일반적으로 3~10\n",
    "              'subsample': 0.9,    ###각 트리마다 관측 데이터 샘플링 비율 0.5~1\n",
    "              'colsample_bytree': 0.9,   ###각 트리마다 변수 샘플링 비율 0.5~1\n",
    "              'alpha':0.001,                    ###규제항 \n",
    "              'random_state': 42, \n",
    "              'verbosity': 1}                ###동작메시지 출력\n",
    "    tr_data = xgb.DMatrix(trn_x, trn_y) \n",
    "    va_data = xgb.DMatrix(val_x, val_y) \n",
    "    watchlist = [(tr_data, 'train'), (va_data, 'valid')] \n",
    "    model_xgb = xgb.train(params, tr_data, 10000, watchlist, maximize=False, early_stopping_rounds = 500, verbose_eval=100) \n",
    "    \n",
    "    test_data = xgb.DMatrix(kfoldTestWithBig) \n",
    "    xgbPre += model_xgb.predict(test_data) / folds.n_splits \n",
    "    xgbOof[val_idx] = model_xgb.predict(va_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(testTarget-xgbPre)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum((testTarget-xgbPre)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###lightgbm 파라미터\n",
    "param = {'num_leaves': 50,               \n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.2,           ###트리만들때마다 0.01 씩 가중치 곱함\n",
    "         \"boosting\": \"gbdt\",                ###워래 우리가 아는 gbdt 씀\n",
    "         \"feature_fraction\": 0.9,          ###변수 90%만 쓰게됨\n",
    "         \"bagging_freq\": 1,                 ###bagging 의빈도\n",
    "         \"bagging_fraction\": 0.9,        ###데이터를 90%만 쓰게됨 resampling 없이\n",
    "         \"bagging_seed\": 11,              ###bagging 을 위한 seed\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 0.1,                  ###오메가 항에서 람다 말할는거임 가중치 옆에 붙는 weights 숫자가 클수록 보수적\n",
    "         \"verbosity\": -1}                      ###보수적이라는말은 트리생성을 잘안할려고함\n",
    "###verbosity -1이 정확하게 어떤기능인지?\n",
    "###bagging을 실행하는데 어떠한 순서로 실행하는건지?\n",
    "###처음에 데이터가있으면\n",
    "###처음에 부스팅 한번할때마다 배깅을 실행한다고한다\n",
    "###즉 kfold에 의해서 트레인데이터가들어오면\n",
    "###이 트레인에서 변수90% 데이터 90% 를뽑는다\n",
    "###이걸로 트리하나만듬 \n",
    "###이때 트리를 총 10개만든다는 소리인가? 그래서 배깅을함???\n",
    "###그뒤에 10개의 weight 값 얻고 난뒤에 learningrate 적용해서 잔차계산하는건가???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm단일모델인데 범주형 변수 제외하고 이거는 가변수 쓰지말고 그냥 big 그대로 쓰자\n",
    "lightgbmOof=np.zeros(len(kfoldDataWithBig))\n",
    "lightgbmPre=np.zeros(len(kfoldTestWithBig))\n",
    "kfoldData2=copy.deepcopy(kfoldData)\n",
    "kfoldTest2=copy.deepcopy(kfoldTest)\n",
    "del kfoldData2['Apart name']\n",
    "del kfoldData2['Street name']\n",
    "del kfoldData2['dong']\n",
    "del kfoldTest2['Apart name']\n",
    "del kfoldTest2['Street name']\n",
    "del kfoldTest2['dong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=KFold(n_splits=5,shuffle=True,random_state=15)\n",
    "feature_importance_df = pd.DataFrame()\n",
    "features=kfoldData2.columns\n",
    "for order, (train_idx,valid_idx) in enumerate(folds.split(kfoldData2, kfoldTarget)):\n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(order + 1))\n",
    "    trn_data = lgb.Dataset(kfoldData2.iloc[train_idx], label=kfoldTarget.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(kfoldData2.iloc[valid_idx], label=kfoldTarget.iloc[valid_idx])\n",
    "\n",
    "    num_round = 10000          ###boosting 10000번 한다는소리임 verbose_eval 은 100번마다 출력함\n",
    "    ###early는 100번동안 효과없으면 그만둠\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], verbose_eval=100, early_stopping_rounds=100)\n",
    "    #훈련해서 모수가 조정된 모델에 valid 데이터 넣어서 예측값 보여주는것\n",
    "    lightgbmOof[valid_idx] = clf.predict(kfoldData2.iloc[valid_idx], num_iteration=clf.best_iteration)\n",
    "    ###5개모델 다더해서 나누면 최종 예측치 되는것\n",
    "    lightgbmPre += clf.predict(kfoldTest2, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"]=features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"order\"] = order + 1\n",
    "    \n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:20].index)\n",
    "###각변수들 평규내서 위에서 상위 1000개뽑는것 근디 총변수가 180개인데 의미있나?\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "                ###900개중에서 해당하는 변수가 중복으로 뽑히게됨 결과로 보니 그런듯\n",
    "    ###그런데 그림으로 그릴때는 이게 합쳐지는듯\n",
    "plt.figure(figsize=(10,15))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(testTarget-lightgbmPre)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum((testTarget-lightgbmPre)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###lightgbm 데이터 다쓰는것 범주형 다쓰는거임\n",
    "lightgbmOof2=np.zeros(len(kfoldData))\n",
    "lightgbmPre2=np.zeros(len(kfoldTest))\n",
    "folds=KFold(n_splits=5,shuffle=True,random_state=15)\n",
    "feature_importance_df2 = pd.DataFrame()\n",
    "features2=kfoldData.columns\n",
    "for order, (train_idx,valid_idx) in enumerate(folds.split(kfoldData, kfoldTarget)):\n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(order + 1))\n",
    "    trn_data = lgb.Dataset(kfoldData.iloc[train_idx], label=kfoldTarget.iloc[train_idx])\n",
    "    val_data = lgb.Dataset(kfoldData.iloc[valid_idx], label=kfoldTarget.iloc[valid_idx])\n",
    "\n",
    "    num_round = 10000          ###boosting 10000번 한다는소리임 verbose_eval 은 100번마다 출력함\n",
    "    ###early는 100번동안 효과없으면 그만둠\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [val_data], verbose_eval=100, early_stopping_rounds=100)\n",
    "    #훈련해서 모수가 조정된 모델에 valid 데이터 넣어서 예측값 보여주는것\n",
    "    lightgbmOof2[valid_idx] = clf.predict(kfoldData.iloc[valid_idx], num_iteration=clf.best_iteration)\n",
    "    ###5개모델 다더해서 나누면 최종 예측치 되는것\n",
    "    lightgbmPre2 += clf.predict(kfoldTest, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df2 = pd.DataFrame()\n",
    "    fold_importance_df2[\"feature\"]=features2\n",
    "    fold_importance_df2[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df2[\"order\"] = order + 1\n",
    "    \n",
    "    feature_importance_df2 = pd.concat([feature_importance_df2, fold_importance_df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df2[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:30].index)\n",
    "###각변수들 평규내서 위에서 상위 1000개뽑는것 근디 총변수가 180개인데 의미있나?\n",
    "best_features = feature_importance_df2.loc[feature_importance_df2.feature.isin(cols)]\n",
    "                ###900개중에서 해당하는 변수가 중복으로 뽑히게됨 결과로 보니 그런듯\n",
    "    ###그런데 그림으로 그릴때는 이게 합쳐지는듯\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"feature\",\n",
    "            y=\"importance\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm단일모델 범주형 다씀\n",
    "(abs(testTarget-lightgbmPre2)/testTarget*100).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-sum((testTarget-lightgbmPre2)**2)/SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
